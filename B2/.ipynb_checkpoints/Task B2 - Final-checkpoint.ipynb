{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"orange\">Load modules</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import sys\n",
    "sys.path.append(\"/Users/macbookpro/UCL - MSc Integrated Machine Learning Systems/Y1/Applied Machine Learning I/Final Assignment/AMLS_20-21_SN17024244\")\n",
    "from _CFG_Task_B import *\n",
    "from _CLASS_ImageManager import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following lines we load the labels .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = load_images_label_csv(\"face_shape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"orange\">Load and process images</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We leverage on the **ImageManager** class object to load the whole set of images as well as crop them based on the body part we are interested in. The processing is based on a Cascade Classifier. We will implement our use case using the Haar Cascade classifier, which is an effective object detection approach which was proposed by Paul Viola and Michael Jones. This is basically a machine learning based approach where a cascade function is trained from a lot of images both positive and negative. Based on the training it is then used to detect the objects in the other images.\n",
    "So how this works is they are huge individual .xml files with a lot of feature sets and each xml corresponds to a very specific type of use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to load images from /Users/macbookpro/UCL - MSc Integrated Machine Learning Systems/Y1/Applied Machine Learning I/Final Assignment/AMLS_20-21_SN17024244/Datasets/dataset_AMLS_20-21/cartoon_set/img/ with extension .png\n",
      "686/10000 images loaded\n",
      "1361/10000 images loaded\n",
      "2065/10000 images loaded\n",
      "2742/10000 images loaded\n",
      "3417/10000 images loaded\n",
      "4176/10000 images loaded\n",
      "5125/10000 images loaded\n",
      "5960/10000 images loaded\n",
      "6724/10000 images loaded\n",
      "7507/10000 images loaded\n",
      "8370/10000 images loaded\n",
      "9194/10000 images loaded\n",
      "9900/10000 images loaded\n",
      "10000/10000 images loaded\n"
     ]
    }
   ],
   "source": [
    "imgmgr = ImageManager()\n",
    "imgmgr.load_images_from_folder(sub_folder, extension, verbose = True,\n",
    "#                               colour = cv2.IMREAD_GRAYSCALE    # B&W conversion\n",
    "                              )\n",
    "imgmgr.bodypart = \"face\"\n",
    "imges = imgmgr.crop_part((256,256), squaring=False, x_offsets=(0,0), y_offsets = (0,0))\n",
    "imges = imgmgr.canny_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = cv2.cvtColor(imges[5], cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"orange\">Solving exercise using various machine learning approches</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our images have been processed, we can split our dataset into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(imges, (10000, 256*256*1))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators = 100, \n",
    "                           max_depth = 12, \n",
    "                           criterion = \"entropy\",\n",
    "                           min_samples_split = 3,\n",
    "                           min_samples_leaf = 4) # Number of trees\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "print(\"TRAIN METRICS\")\n",
    "print(sklearn.metrics.classification_report(y_train, y_pred_train))\n",
    "print(\"TEST METRICS\")\n",
    "print(sklearn.metrics.classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=np.arange(5, 100, 5)\n",
    "\n",
    "# Dictionary containing (<n_estimators>, <error rate>) pairs.\n",
    "d = {}\n",
    "\n",
    "for x in n_estimators:\n",
    "    clf.set_params(n_estimators=x)\n",
    "    clf.fit(X_train, y_train)\n",
    "    error = 1 - clf.score(X_test, y_test)\n",
    "    d[x] = error\n",
    "\n",
    "plt.plot(d.keys(), d.values())\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"Error rate\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title('Backtesting performance of number of trees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present the confusion matrix once data has been trained using Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_confusion_matrix(y_train, y_pred_train, y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(10000,256, 256,1)\n",
    "\n",
    "print(X.dtype, X.min(), X.max(), X.shape)\n",
    "print(y.dtype, y.min(), y.max(), y.shape)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model\n",
    "nb_filters = 16\n",
    "nb_pool = 8\n",
    "nb_conv = 8\n",
    "nb_classes = 5\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(nb_filters, (nb_conv, nb_conv), activation='relu', input_shape=X.shape[1:]))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Conv2D(nb_filters, (nb_conv, nb_conv), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(nb_classes))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=10, \n",
    "                    validation_data=(X_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
